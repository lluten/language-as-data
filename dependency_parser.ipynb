{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b0f2fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy_udpipe\n",
    "from spacy_udpipe import download, load\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74f691f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded pre-trained UDPipe model for 'sk' language\n",
      "Slovak model: slovak-snk-ud-2.5-191206.udpipe\n",
      "Already downloaded a model for the 'tr' language\n",
      "Turkish model: turkish-imst-ud-2.5-191206.udpipe\n"
     ]
    }
   ],
   "source": [
    "# download and load Slovak and Turkish models\n",
    "\n",
    "download(\"sk\")\n",
    "slovak_model = load(\"sk\")\n",
    "model_dir = os.path.join(os.path.dirname(spacy_udpipe.__file__), 'models')\n",
    "for filename in os.listdir(model_dir):\n",
    "    if 'slovak' in filename.lower() and filename.endswith('.udpipe'):\n",
    "        print(f\"Slovak model: {filename}\")\n",
    "        break\n",
    "\n",
    "download(\"tr\")\n",
    "turkish_model = load(\"tr\")\n",
    "model_dir = os.path.join(os.path.dirname(spacy_udpipe.__file__), 'models')\n",
    "for filename in os.listdir(model_dir):\n",
    "    if 'turkish' in filename.lower() and filename.endswith('.udpipe'):\n",
    "        print(f\"Turkish model: {filename}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22637a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toto\ttoto\tDET\tnsubj\ttestovacia\n",
      "je\tbyť\tAUX\tcop\ttestovacia\n",
      "testovacia\ttestovacia\tNOUN\tROOT\ttestovacia\n",
      "veta\tveta\tNOUN\tnmod\ttestovacia\n",
      ".\t.\tPUNCT\tpunct\ttestovacia\n",
      "\n",
      "Bu\tbu\tDET\tdet\ttest\n",
      "bir\tbir\tNUM\tdet\ttest\n",
      "test\ttest\tNOUN\tnmod:poss\tcümlesi\n",
      "cümlesi\tcümle\tNOUN\tROOT\tcümlesi\n",
      "dir\ti\tAUX\tcop\tcümlesi\n",
      ".\t.\tPUNCT\tpunct\tcümlesi\n"
     ]
    }
   ],
   "source": [
    "slovak_test_sentence = \"Toto je testovacia veta.\"\n",
    "parsed_doc = slovak_model(slovak_test_sentence)\n",
    "for token in parsed_doc:\n",
    "    print(f\"{token.text}\\t{token.lemma_}\\t{token.pos_}\\t{token.dep_}\\t{token.head.text}\")\n",
    "print()\n",
    "turkish_test_sentence = \"Bu bir test cümlesidir.\"\n",
    "parsed_doc = turkish_model(turkish_test_sentence)\n",
    "for token in parsed_doc:\n",
    "    print(f\"{token.text}\\t{token.lemma_}\\t{token.pos_}\\t{token.dep_}\\t{token.head.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d24746c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/slk_newscrawl_2016_1M/slk_newscrawl_2016_1M-sentences.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    slk_df = pd.DataFrame(\n",
    "        [line.strip().split(\"\\t\")[1] for line in f.readlines()], columns=[\"sentence\"]\n",
    "    )\n",
    "\n",
    "with open(\"data/tur_news_2024_1M/tur_news_2024_1M-sentences.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    tur_df = pd.DataFrame(\n",
    "        [line.strip().split(\"\\t\")[1] for line in f.readlines()], columns=[\"sentence\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f4d5951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes around 5 mins for each (still not the full datasets)\n",
    "\n",
    "slk_sample_df = slk_df.head(10000).copy()\n",
    "slk_parsed_docs = list(slovak_model.pipe(slk_sample_df['sentence']))\n",
    "slk_sample_df['parsed_doc'] = slk_parsed_docs\n",
    "\n",
    "tur_sample_df = tur_df.head(10000).copy()\n",
    "tur_parsed_docs = list(turkish_model.pipe(tur_sample_df['sentence']))\n",
    "tur_sample_df['parsed_doc'] = tur_parsed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4629799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependency_info(parsed_doc):\n",
    "    print(f\"{'Text':<15} {'POS':<10} {'Dependency':<15} {'Head Text':<15}\")\n",
    "    print(\"-\" * 55)\n",
    "    for token in parsed_doc:\n",
    "        print(f\"{token.text:<15} {token.pos_:<10} {token.dep_:<15} {token.head.text:<15}\")\n",
    "\n",
    "def sentence_depth(parsed_doc):\n",
    "    if not parsed_doc:\n",
    "        return 0\n",
    "    def token_depth(token):\n",
    "        if token.head == token:\n",
    "            return 0\n",
    "        return 1 + token_depth(token.head)\n",
    "    return max(token_depth(token) for token in parsed_doc) if len(parsed_doc) > 0 else 0\n",
    "\n",
    "def leaf_node_pos(parsed_doc):\n",
    "    leaf_pos_tags = []\n",
    "    for token in parsed_doc:\n",
    "        if len(list(token.children)) == 0:\n",
    "            leaf_pos_tags.append(token.pos_)\n",
    "    return leaf_pos_tags\n",
    "\n",
    "#  a token's degree is the number of its direct children\n",
    "def corpus_degree_distribution(parsed_docs):\n",
    "    corpus_degree_counts = Counter()\n",
    "    for doc in parsed_docs:\n",
    "        for token in doc:\n",
    "            degree = len(list(token.children))\n",
    "            corpus_degree_counts[degree] += 1  \n",
    "    return corpus_degree_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28b995de",
   "metadata": {},
   "outputs": [],
   "source": [
    "slk_sample_df['tree_depth'] = slk_sample_df['parsed_doc'].apply(sentence_depth)\n",
    "slk_sample_df['leaf_nodes'] = slk_sample_df['parsed_doc'].apply(leaf_node_pos)\n",
    "\n",
    "tur_sample_df['tree_depth'] = tur_sample_df['parsed_doc'].apply(sentence_depth)\n",
    "tur_sample_df['leaf_nodes'] = tur_sample_df['parsed_doc'].apply(leaf_node_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adb2d502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average tree depth: 4.21\n",
      "\n",
      "top 10 most common leaf node categories:\n",
      "PUNCT: 28531\n",
      "ADP: 15212\n",
      "ADJ: 13137\n",
      "CCONJ: 8250\n",
      "NOUN: 6875\n",
      "PRON: 6751\n",
      "DET: 6243\n",
      "ADV: 5691\n",
      "PART: 5602\n",
      "SCONJ: 4988\n",
      "\n",
      "degree distribution for Slovak corpus:\n",
      "degree 0: 114225 tokens\n",
      "degree 1: 28555 tokens\n",
      "degree 2: 17346 tokens\n",
      "degree 3: 9650 tokens\n",
      "degree 4: 7286 tokens\n",
      "degree 5: 4813 tokens\n",
      "degree 6: 2384 tokens\n",
      "degree 7: 1048 tokens\n",
      "degree 8: 458 tokens\n",
      "degree 9: 185 tokens\n",
      "degree 10: 79 tokens\n",
      "degree 11: 41 tokens\n",
      "degree 12: 18 tokens\n",
      "degree 13: 9 tokens\n",
      "degree 14: 4 tokens\n",
      "degree 15: 2 tokens\n",
      "degree 16: 2 tokens\n",
      "degree 18: 1 tokens\n"
     ]
    }
   ],
   "source": [
    "# slovak\n",
    "\n",
    "# average tree depth\n",
    "avg_depth = slk_sample_df['tree_depth'].mean()\n",
    "print(f\"average tree depth: {avg_depth:.2f}\")\n",
    "\n",
    "# most common leaf node categories\n",
    "all_leaf_nodes = [pos for sublist in slk_sample_df['leaf_nodes'] for pos in sublist]\n",
    "leaf_node_distribution = Counter(all_leaf_nodes)\n",
    "print(\"\\ntop 10 most common leaf node categories:\")\n",
    "for pos, count in leaf_node_distribution.most_common(10):\n",
    "    print(f\"{pos}: {count}\")\n",
    "\n",
    "# degree distribution\n",
    "print('\\ndegree distribution for Slovak corpus:')\n",
    "for degree, count in sorted(corpus_degree_distribution(slk_parsed_docs).items()):\n",
    "    print(f\"degree {degree}: {count} tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6975be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average tree depth: 5.79\n",
      "\n",
      "top 10 most common leaf node categories:\n",
      "PUNCT: 24040\n",
      "NOUN: 21256\n",
      "ADJ: 9398\n",
      "PROPN: 9212\n",
      "NUM: 7789\n",
      "ADP: 7768\n",
      "CCONJ: 5839\n",
      "VERB: 5579\n",
      "ADV: 2514\n",
      "DET: 1651\n",
      "\n",
      "degree distribution for Turkish corpus:\n",
      "degree 0: 97245 tokens\n",
      "degree 1: 46380 tokens\n",
      "degree 2: 27459 tokens\n",
      "degree 3: 11319 tokens\n",
      "degree 4: 5012 tokens\n",
      "degree 5: 2433 tokens\n",
      "degree 6: 1092 tokens\n",
      "degree 7: 510 tokens\n",
      "degree 8: 229 tokens\n",
      "degree 9: 116 tokens\n",
      "degree 10: 47 tokens\n",
      "degree 11: 22 tokens\n",
      "degree 12: 7 tokens\n",
      "degree 13: 5 tokens\n",
      "degree 14: 1 tokens\n",
      "degree 15: 2 tokens\n",
      "degree 16: 2 tokens\n"
     ]
    }
   ],
   "source": [
    "# turkish\n",
    "\n",
    "# average tree depth\n",
    "avg_depth = tur_sample_df['tree_depth'].mean()\n",
    "print(f\"average tree depth: {avg_depth:.2f}\")\n",
    "\n",
    "# most common leaf node categories\n",
    "all_leaf_nodes = [pos for sublist in tur_sample_df['leaf_nodes'] for pos in sublist]\n",
    "leaf_node_distribution = Counter(all_leaf_nodes)\n",
    "print(\"\\ntop 10 most common leaf node categories:\")\n",
    "for pos, count in leaf_node_distribution.most_common(10):\n",
    "    print(f\"{pos}: {count}\")\n",
    "\n",
    "# degree distribution\n",
    "print('\\ndegree distribution for Turkish corpus:')\n",
    "for degree, count in sorted(corpus_degree_distribution(tur_parsed_docs).items()):\n",
    "    print(f\"degree {degree}: {count} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b06dea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_distance_to_root(token):\n",
    "    \"\"\"Calculates the number of head links to reach the root.\"\"\"\n",
    "    if token.head == token:\n",
    "        return 0\n",
    "    # Use len(list(token.ancestors)) for a simpler implementation\n",
    "    return len(list(token.ancestors))\n",
    "\n",
    "def corpus_pos_distance_to_root(parsed_docs, target_pos_list):\n",
    "    \"\"\"Calculates the average distance to root for specified POS tags.\"\"\"\n",
    "    pos_distances = {pos: [] for pos in target_pos_list}\n",
    "    \n",
    "    for doc in parsed_docs:\n",
    "        for token in doc:\n",
    "            if token.pos_ in target_pos_list:\n",
    "                distance = token_distance_to_root(token)\n",
    "                pos_distances[token.pos_].append(distance)\n",
    "                \n",
    "    # Calculate the average for each POS\n",
    "    avg_distances = {}\n",
    "    for pos, distances in pos_distances.items():\n",
    "        if distances:\n",
    "            avg_distances[pos] = sum(distances) / len(distances)\n",
    "        else:\n",
    "            avg_distances[pos] = 0\n",
    "            \n",
    "    return avg_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e312d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_ancestor_patterns(parsed_docs, target_pos, n=10):\n",
    "    \"\"\"Finds the most common POS of the head for a target POS.\"\"\"\n",
    "    ancestor_pos_counts = Counter()\n",
    "    for doc in parsed_docs:\n",
    "        for token in doc:\n",
    "            if token.pos_ == target_pos and token.head != token:\n",
    "                # The pattern is: (Dependency Label, Head POS)\n",
    "                ancestor_pos_counts[(token.dep_, token.head.pos_)] += 1\n",
    "    \n",
    "    print(f\"\\nTop {n} Ancestor Patterns for {target_pos}:\")\n",
    "    for pattern, count in ancestor_pos_counts.most_common(n):\n",
    "        print(f\"  {pattern[0]:<5} (governed by {pattern[1]}): {count}\")\n",
    "\n",
    "\n",
    "def corpus_descendant_patterns(parsed_docs, target_pos, n=10):\n",
    "    \"\"\"Finds the most common dependency labels of children for a target POS.\"\"\"\n",
    "    descendant_dep_counts = Counter()\n",
    "    for doc in parsed_docs:\n",
    "        for token in doc:\n",
    "            if token.pos_ == target_pos:\n",
    "                for child in token.children:\n",
    "                    descendant_dep_counts[child.dep_] += 1\n",
    "    \n",
    "    print(f\"\\nTop {n} Descendant Relations for {target_pos}:\")\n",
    "    for dep, count in descendant_dep_counts.most_common(n):\n",
    "        print(f\"  {dep:<10}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f33f093d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average distance to root for Slovak POS:\n",
      "NOUN   : 2.41\n",
      "VERB   : 1.10\n",
      "ADJ    : 3.19\n",
      "DET    : 2.89\n",
      "CCONJ  : 2.46\n",
      "ADP    : 3.50\n",
      "ADV    : 2.25\n",
      "PUNCT  : 2.31\n",
      "PRON   : 2.12\n",
      "PART   : 2.26\n",
      "SCONJ  : 2.44\n",
      "PROPN  : 2.42\n",
      "NUM    : 2.65\n",
      "\n",
      "Average distance to root for Turkish POS:\n",
      "NOUN   : 3.43\n",
      "VERB   : 2.14\n",
      "ADJ    : 3.74\n",
      "DET    : 3.92\n",
      "CCONJ  : 4.42\n",
      "ADP    : 4.33\n",
      "ADV    : 3.22\n",
      "PUNCT  : 2.31\n",
      "PRON   : 2.83\n",
      "PART   : 0.00\n",
      "SCONJ  : 0.00\n",
      "PROPN  : 3.87\n",
      "NUM    : 3.80\n"
     ]
    }
   ],
   "source": [
    "#Average Distance to Root\n",
    "\n",
    "TARGET_POS = [\"NOUN\", \"VERB\", \"ADJ\", \"DET\", \"CCONJ\", \"ADP\", \"ADV\", \"PUNCT\", \"PRON\", \"PART\", \"SCONJ\", \"PROPN\", \"NUM\"]\n",
    "\n",
    "# Slovak\n",
    "slk_avg_dist = corpus_pos_distance_to_root(slk_parsed_docs, TARGET_POS)\n",
    "print(\"\\nAverage distance to root for Slovak POS:\")\n",
    "for pos, avg_dist in slk_avg_dist.items():\n",
    "    print(f\"{pos:<7}: {avg_dist:.2f}\")\n",
    "\n",
    "# Turkish\n",
    "tur_avg_dist = corpus_pos_distance_to_root(tur_parsed_docs, TARGET_POS)\n",
    "print(\"\\nAverage distance to root for Turkish POS:\")\n",
    "for pos, avg_dist in tur_avg_dist.items():\n",
    "    print(f\"{pos:<7}: {avg_dist:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e3f799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
