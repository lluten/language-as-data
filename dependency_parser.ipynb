{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b0f2fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy_udpipe\n",
    "from spacy_udpipe import download, load\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f691f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded a model for the 'sk' language\n",
      "Slovak model: slovak-snk-ud-2.5-191206.udpipe\n",
      "Downloaded pre-trained UDPipe model for 'tr' language\n",
      "Turkish model: turkish-imst-ud-2.5-191206.udpipe\n"
     ]
    }
   ],
   "source": [
    "# download and load Slovak and Turkish models\n",
    "\n",
    "download(\"sk\")\n",
    "slovak_model = load(\"sk\")\n",
    "model_dir = os.path.join(os.path.dirname(spacy_udpipe.__file__), 'models')\n",
    "for filename in os.listdir(model_dir):\n",
    "    if 'slovak' in filename.lower() and filename.endswith('.udpipe'):\n",
    "        print(f\"Slovak model: {filename}\")\n",
    "        break\n",
    "\n",
    "download(\"tr\")\n",
    "turkish_model = load(\"tr\")\n",
    "model_dir = os.path.join(os.path.dirname(spacy_udpipe.__file__), 'models')\n",
    "for filename in os.listdir(model_dir):\n",
    "    if 'turkish' in filename.lower() and filename.endswith('.udpipe'):\n",
    "        print(f\"Turkish model: {filename}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "22637a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toto\ttoto\tDET\tnsubj\ttestovacia\n",
      "je\tbyť\tAUX\tcop\ttestovacia\n",
      "testovacia\ttestovacia\tNOUN\tROOT\ttestovacia\n",
      "veta\tveta\tNOUN\tnmod\ttestovacia\n",
      ".\t.\tPUNCT\tpunct\ttestovacia\n",
      "\n",
      "Bu\tbu\tDET\tdet\ttest\n",
      "bir\tbir\tNUM\tdet\ttest\n",
      "test\ttest\tNOUN\tnmod:poss\tcümlesi\n",
      "cümlesi\tcümle\tNOUN\tROOT\tcümlesi\n",
      "dir\ti\tAUX\tcop\tcümlesi\n",
      ".\t.\tPUNCT\tpunct\tcümlesi\n"
     ]
    }
   ],
   "source": [
    "slovak_test_sentence = \"Toto je testovacia veta.\"\n",
    "parsed_doc = slovak_model(slovak_test_sentence)\n",
    "for token in parsed_doc:\n",
    "    print(f\"{token.text}\\t{token.lemma_}\\t{token.pos_}\\t{token.dep_}\\t{token.head.text}\")\n",
    "print()\n",
    "turkish_test_sentence = \"Bu bir test cümlesidir.\"\n",
    "parsed_doc = turkish_model(turkish_test_sentence)\n",
    "for token in parsed_doc:\n",
    "    print(f\"{token.text}\\t{token.lemma_}\\t{token.pos_}\\t{token.dep_}\\t{token.head.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d24746c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/slk_newscrawl_2016_1M/slk_newscrawl_2016_1M-sentences.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    slk_df = pd.DataFrame(\n",
    "        [line.strip().split(\"\\t\")[1] for line in f.readlines()], columns=[\"sentence\"]\n",
    "    )\n",
    "\n",
    "with open(\"data/tur_news_2024_1M/tur_news_2024_1M-sentences.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    tur_df = pd.DataFrame(\n",
    "        [line.strip().split(\"\\t\")[1] for line in f.readlines()], columns=[\"sentence\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4d5951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes around 5 mins for each (still not the full datasets)\n",
    "\n",
    "slk_sample_df = slk_df.head(10000).copy()\n",
    "slk_parsed_docs = list(slovak_model.pipe(slk_sample_df['sentence']))\n",
    "slk_sample_df['parsed_doc'] = slk_parsed_docs\n",
    "\n",
    "tur_sample_df = tur_df.head(10000).copy()\n",
    "tur_parsed_docs = list(turkish_model.pipe(tur_sample_df['sentence']))\n",
    "tur_sample_df['parsed_doc'] = tur_parsed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c4629799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependency_info(parsed_doc):\n",
    "    print(f\"{'Text':<15} {'POS':<10} {'Dependency':<15} {'Head Text':<15}\")\n",
    "    print(\"-\" * 55)\n",
    "    for token in parsed_doc:\n",
    "        print(f\"{token.text:<15} {token.pos_:<10} {token.dep_:<15} {token.head.text:<15}\")\n",
    "\n",
    "def sentence_depth(parsed_doc):\n",
    "    if not parsed_doc:\n",
    "        return 0\n",
    "    def token_depth(token):\n",
    "        if token.head == token:\n",
    "            return 0\n",
    "        return 1 + token_depth(token.head)\n",
    "    return max(token_depth(token) for token in parsed_doc) if len(parsed_doc) > 0 else 0\n",
    "\n",
    "def leaf_node_pos(parsed_doc):\n",
    "    leaf_pos_tags = []\n",
    "    for token in parsed_doc:\n",
    "        if len(list(token.children)) == 0:\n",
    "            leaf_pos_tags.append(token.pos_)\n",
    "    return leaf_pos_tags\n",
    "\n",
    "#  a token's degree is the number of its direct children\n",
    "def corpus_degree_distribution(parsed_docs):\n",
    "    corpus_degree_counts = Counter()\n",
    "    for doc in parsed_docs:\n",
    "        for token in doc:\n",
    "            degree = len(list(token.children))\n",
    "            corpus_degree_counts[degree] += 1  \n",
    "    return corpus_degree_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "28b995de",
   "metadata": {},
   "outputs": [],
   "source": [
    "slk_sample_df['tree_depth'] = slk_sample_df['parsed_doc'].apply(sentence_depth)\n",
    "slk_sample_df['leaf_nodes'] = slk_sample_df['parsed_doc'].apply(leaf_node_pos)\n",
    "\n",
    "tur_sample_df['tree_depth'] = tur_sample_df['parsed_doc'].apply(sentence_depth)\n",
    "tur_sample_df['leaf_nodes'] = tur_sample_df['parsed_doc'].apply(leaf_node_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "adb2d502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average tree depth: 4.21\n",
      "\n",
      "top 10 most common leaf node categories:\n",
      "PUNCT: 28531\n",
      "ADP: 15212\n",
      "ADJ: 13137\n",
      "CCONJ: 8250\n",
      "NOUN: 6875\n",
      "PRON: 6751\n",
      "DET: 6243\n",
      "ADV: 5691\n",
      "PART: 5602\n",
      "SCONJ: 4988\n",
      "\n",
      "degree distribution for Slovak corpus:\n",
      "degree 0: 114225 tokens\n",
      "degree 1: 28555 tokens\n",
      "degree 2: 17346 tokens\n",
      "degree 3: 9650 tokens\n",
      "degree 4: 7286 tokens\n",
      "degree 5: 4813 tokens\n",
      "degree 6: 2384 tokens\n",
      "degree 7: 1048 tokens\n",
      "degree 8: 458 tokens\n",
      "degree 9: 185 tokens\n",
      "degree 10: 79 tokens\n",
      "degree 11: 41 tokens\n",
      "degree 12: 18 tokens\n",
      "degree 13: 9 tokens\n",
      "degree 14: 4 tokens\n",
      "degree 15: 2 tokens\n",
      "degree 16: 2 tokens\n",
      "degree 18: 1 tokens\n"
     ]
    }
   ],
   "source": [
    "# slovak\n",
    "\n",
    "# average tree depth\n",
    "avg_depth = slk_sample_df['tree_depth'].mean()\n",
    "print(f\"average tree depth: {avg_depth:.2f}\")\n",
    "\n",
    "# most common leaf node categories\n",
    "all_leaf_nodes = [pos for sublist in slk_sample_df['leaf_nodes'] for pos in sublist]\n",
    "leaf_node_distribution = Counter(all_leaf_nodes)\n",
    "print(\"\\ntop 10 most common leaf node categories:\")\n",
    "for pos, count in leaf_node_distribution.most_common(10):\n",
    "    print(f\"{pos}: {count}\")\n",
    "\n",
    "# degree distribution\n",
    "print('\\ndegree distribution for Slovak corpus:')\n",
    "for degree, count in sorted(corpus_degree_distribution(slk_parsed_docs).items()):\n",
    "    print(f\"degree {degree}: {count} tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b6975be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average tree depth: 5.79\n",
      "\n",
      "top 10 most common leaf node categories:\n",
      "PUNCT: 24040\n",
      "NOUN: 21256\n",
      "ADJ: 9398\n",
      "PROPN: 9212\n",
      "NUM: 7789\n",
      "ADP: 7768\n",
      "CCONJ: 5839\n",
      "VERB: 5579\n",
      "ADV: 2514\n",
      "DET: 1651\n",
      "\n",
      "degree distribution for Turkish corpus:\n",
      "degree 0: 97245 tokens\n",
      "degree 1: 46380 tokens\n",
      "degree 2: 27459 tokens\n",
      "degree 3: 11319 tokens\n",
      "degree 4: 5012 tokens\n",
      "degree 5: 2433 tokens\n",
      "degree 6: 1092 tokens\n",
      "degree 7: 510 tokens\n",
      "degree 8: 229 tokens\n",
      "degree 9: 116 tokens\n",
      "degree 10: 47 tokens\n",
      "degree 11: 22 tokens\n",
      "degree 12: 7 tokens\n",
      "degree 13: 5 tokens\n",
      "degree 14: 1 tokens\n",
      "degree 15: 2 tokens\n",
      "degree 16: 2 tokens\n"
     ]
    }
   ],
   "source": [
    "# turkish\n",
    "\n",
    "# average tree depth\n",
    "avg_depth = tur_sample_df['tree_depth'].mean()\n",
    "print(f\"average tree depth: {avg_depth:.2f}\")\n",
    "\n",
    "# most common leaf node categories\n",
    "all_leaf_nodes = [pos for sublist in tur_sample_df['leaf_nodes'] for pos in sublist]\n",
    "leaf_node_distribution = Counter(all_leaf_nodes)\n",
    "print(\"\\ntop 10 most common leaf node categories:\")\n",
    "for pos, count in leaf_node_distribution.most_common(10):\n",
    "    print(f\"{pos}: {count}\")\n",
    "\n",
    "# degree distribution\n",
    "print('\\ndegree distribution for Turkish corpus:')\n",
    "for degree, count in sorted(corpus_degree_distribution(tur_parsed_docs).items()):\n",
    "    print(f\"degree {degree}: {count} tokens\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
